path = "/mnt/data-artemis/pavlo/pycharm_project_318/data/MT/wmt23-no-crawls/wmt23-deen"

de = "train.deu"
en = "train.eng"
test = "test.csv"


ds_de = None
ds_en = None

with open(f"{path}/{de}", "r") as f:

    ds_de = f.readlines()

with open(f"{path}/{en}", "r") as f:

    ds_en = f.readlines()


import pandas as pd

df = pd.DataFrame(
    {"de": [sample[:-1] for sample in ds_de], "en": [sample[:-1] for sample in ds_en]}
)


import torch

# Set the torch random generator seed
torch.manual_seed(0)

# Assuming "df" has already been loaded

# Total number of rows in the DataFrame
total_rows = len(df)

# Generate a permutation of all indices
all_indices = torch.randperm(total_rows)

# Separate indices for training and validation, ensuring no overlap
train_indices = all_indices[:5000000]  # First 5M indices for training
validation_indices = all_indices[5000000:5005000]  # Next 5k indices for validation

# Use the indices to select samples from the DataFrame
train_data = df.iloc[train_indices.numpy()]
validation_data = df.iloc[validation_indices.numpy()]

# You now have train_data with 5M entries and validation_data with 3K entries,
# both selected based on indices generated by the torch random seed.

test = pd.read_csv(f"{path}/{test}")

from datasets import DatasetDict, Dataset

ds_dict = DatasetDict(
    {
        "train": Dataset.from_pandas(train_data).select_columns(["de", "en"]),
        "validation": Dataset.from_pandas(validation_data).select_columns(["de", "en"]),
        "test": Dataset.from_pandas(test),
    }
)
ds_dict

ds_dict.save_to_disk("data/ds/wmt23/de-en")
